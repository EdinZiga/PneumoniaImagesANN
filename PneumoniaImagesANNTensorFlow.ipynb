{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CS404 Artifical Intelligence Project\n",
    "##Supplementary code to go with paper\n",
    "##Adnan Silajdzic\n",
    "##Edin Ziga\n",
    "##Mirza Redzepovic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dee8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install tqdm\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install pydot\n",
    "!pip install pydot_ng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e76dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydot\n",
    "import graphviz\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#TensorFlow implementation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57d89d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Normal Training Data: 100%|████████████████████████████████████████████████| 1341/1341 [00:21<00:00, 63.35it/s]\n",
      "Loading Pneumonia Training Data: 100%|████████████████████████████████████████████| 3875/3875 [00:20<00:00, 193.25it/s]\n",
      "Loading Normal Testing Data: 100%|███████████████████████████████████████████████████| 234/234 [00:02<00:00, 87.53it/s]\n",
      "Loading Pneumonia Testing Data: 100%|███████████████████████████████████████████████| 390/390 [00:01<00:00, 231.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images successfully loaded\n",
      "All images are grayscaled and are 48 by 48\n",
      "Training data size - 5216\n",
      "Testing data size - 624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#LOAD IMAGES\n",
    "\n",
    "# Parameters\n",
    "imageSize = 48\n",
    "# Set the desired size (in this case, 28x28)\n",
    "size = (imageSize, imageSize)\n",
    "\n",
    "#Directory of chest_xray\\train\\NORMAL\n",
    "directory = r\"D:\\PythonProjects\\PneumoninaANN\\chest_xray\\train\\NORMAL\"\n",
    "\n",
    "NormalTraining = []\n",
    "for filename in tqdm(os.listdir(directory), desc = \"Loading Normal Training Data\"):\n",
    "    # Load the image\n",
    "    image = Image.open(os.path.join(directory, filename))\n",
    "    image = image.convert('L')\n",
    "    image = image.resize(size)\n",
    "    pixels = list(image.getdata())\n",
    "    pixels_normalized = [pixel/255.0 for pixel in pixels]\n",
    "    NormalTraining.append(pixels_normalized)\n",
    "    \n",
    "#Directory of chest_xray\\train\\PNEUMONIA\n",
    "directory = r\"D:\\PythonProjects\\PneumoninaANN\\chest_xray\\train\\PNEUMONIA\"\n",
    "\n",
    "PneumoniaTraining = []\n",
    "for filename in tqdm(os.listdir(directory), desc = \"Loading Pneumonia Training Data\"):\n",
    "    image = Image.open(os.path.join(directory, filename))\n",
    "    image = image.convert('L')\n",
    "    image = image.resize(size)\n",
    "    pixels = list(image.getdata())\n",
    "    pixels_normalized = [pixel/255.0 for pixel in pixels]\n",
    "    PneumoniaTraining.append(pixels_normalized)\n",
    "\n",
    "#Directory of chest_xray\\test\\NORMAL\n",
    "directory = r\"D:\\PythonProjects\\PneumoninaANN\\chest_xray\\test\\NORMAL\"  \n",
    "    \n",
    "NormalTesting = []\n",
    "for filename in tqdm(os.listdir(directory), desc = \"Loading Normal Testing Data\"):\n",
    "    image = Image.open(os.path.join(directory, filename))\n",
    "    image = image.convert('L')\n",
    "    image = image.resize(size)\n",
    "    pixels = list(image.getdata())\n",
    "    pixels_normalized = [pixel/255.0 for pixel in pixels]\n",
    "    NormalTesting.append(pixels_normalized)\n",
    "\n",
    "#Directory of chest_xray\\test\\PNEUMONIA\n",
    "directory = r\"D:\\PythonProjects\\PneumoninaANN\\chest_xray\\test\\PNEUMONIA\"\n",
    "    \n",
    "PneumoniaTesting = []\n",
    "for filename in tqdm(os.listdir(directory), desc = \"Loading Pneumonia Testing Data\"):\n",
    "    # Load the image\n",
    "    image = Image.open(os.path.join(directory, filename))\n",
    "    image = image.convert('L')\n",
    "    image = image.resize(size)\n",
    "    pixels = list(image.getdata())\n",
    "    pixels_normalized = [pixel/255.0 for pixel in pixels]\n",
    "    PneumoniaTesting.append(pixels_normalized)\n",
    "    \n",
    "print(\"Images successfully loaded\")\n",
    "print(f\"All images are grayscaled and are {imageSize} by {imageSize}\")\n",
    "\n",
    "training_data = NormalTraining + PneumoniaTraining\n",
    "testing_data = NormalTesting + PneumoniaTesting\n",
    "\n",
    "training_labels = [0]*len(NormalTraining) + [1]*len(PneumoniaTraining)\n",
    "testing_labels = [0]*len(NormalTesting) + [1]*len(PneumoniaTesting)\n",
    "\n",
    "print(f\"Training data size - {len(training_data)}\")\n",
    "print(f\"Testing data size - {len(testing_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4727388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data full size - 5216\n",
      "Testing data full size - 624\n",
      "Training data sample size - 1800\n",
      "Testing data sample size - 200\n",
      "No. epochs selected - 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Training Data: 100%|███████████████████████████████████████████████████| 1800/1800 [00:00<00:00, 300320.11it/s]\n",
      "Loading Testing Data: 100%|██████████████████████████████████████████████████████████████████| 200/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "29/29 [==============================] - 2s 34ms/step - loss: 0.8722 - accuracy: 0.5261\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.5689 - accuracy: 0.7078\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.4897 - accuracy: 0.7817\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.4026 - accuracy: 0.8306\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.2920 - accuracy: 0.8817\n",
      "Epoch 6/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.2441 - accuracy: 0.9089\n",
      "Epoch 7/15\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 0.2161 - accuracy: 0.9178\n",
      "Epoch 8/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1713 - accuracy: 0.9333\n",
      "Epoch 9/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1814 - accuracy: 0.9372\n",
      "Epoch 10/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1728 - accuracy: 0.9339\n",
      "Epoch 11/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1592 - accuracy: 0.9444\n",
      "Epoch 12/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.2260 - accuracy: 0.9167\n",
      "Epoch 13/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1753 - accuracy: 0.9333\n",
      "Epoch 14/15\n",
      "29/29 [==============================] - 1s 33ms/step - loss: 0.1538 - accuracy: 0.9378\n",
      "Epoch 15/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.1993 - accuracy: 0.9233\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8150\n",
      "Test Loss: 0.39077770709991455\n",
      "Test Accuracy: 0.8149999976158142\n"
     ]
    }
   ],
   "source": [
    "#RANDOM SAMPLING WITH REPLACEMENT\n",
    "print(f'Training data full size - {len(training_data)}')\n",
    "print(f'Testing data full size - {len(testing_data)}')\n",
    "\n",
    "#Parameters\n",
    "trainingDataSize = 1800\n",
    "testingDataSize = 200\n",
    "noEpochs = 15\n",
    "\n",
    "print(f'Training data sample size - {trainingDataSize}')\n",
    "print(f'Testing data sample size - {testingDataSize}')\n",
    "print(f'No. epochs selected - {noEpochs}')\n",
    "\n",
    "training_data_sample=[]\n",
    "training_labels_sample=[]\n",
    "\n",
    "testing_data_sample=[]\n",
    "testing_labels_sample=[]\n",
    "\n",
    "for i in tqdm(range(trainingDataSize), desc = \"Loading Training Data\"):\n",
    "    randNum = random.randint(0, 1)\n",
    "    if randNum == 0:\n",
    "        randData = random.randint(0, len(NormalTraining)-1)\n",
    "        training_data_sample.append(NormalTraining[randData])\n",
    "        training_labels_sample.append(0)\n",
    "    else:\n",
    "        randData = random.randint(0, len(PneumoniaTraining)-1)\n",
    "        training_data_sample.append(PneumoniaTraining[randData])\n",
    "        training_labels_sample.append(1)\n",
    "        \n",
    "        \n",
    "for i in tqdm(range(testingDataSize), desc = \"Loading Testing Data\"):\n",
    "    randNum = random.randint(0, 1)\n",
    "    if randNum == 0:\n",
    "        randData = random.randint(0, len(NormalTesting)-1)\n",
    "        testing_data_sample.append(NormalTesting[randData])\n",
    "        testing_labels_sample.append(0)\n",
    "    else:\n",
    "        randData = random.randint(0, len(PneumoniaTesting)-1)\n",
    "        testing_data_sample.append(PneumoniaTesting[randData])\n",
    "        testing_labels_sample.append(1)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, activation='tanh', input_dim=imageSize*imageSize))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Loading Model')\n",
    "model.fit(training_data_sample, training_labels_sample, epochs=noEpochs, batch_size=64)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(testing_data_sample, testing_labels_sample)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85db570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data full size - 5216\n",
      "Testing data full size - 624\n",
      "Training data sample size - 1800\n",
      "Testing data sample size - 200\n",
      "No. epochs selected - 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Training Data: 100%|████████████████████████████████████████████████████| 1800/1800 [00:00<00:00, 62130.17it/s]\n",
      "Loading Testing Data: 100%|██████████████████████████████████████████████████████| 200/200 [00:00<00:00, 100066.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "29/29 [==============================] - 2s 36ms/step - loss: 0.9525 - accuracy: 0.4950\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 0.6582 - accuracy: 0.6289\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.4004 - accuracy: 0.8328\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.3071 - accuracy: 0.8778\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.2547 - accuracy: 0.9006\n",
      "Epoch 6/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.1839 - accuracy: 0.9289\n",
      "Epoch 7/15\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2539 - accuracy: 0.8967\n",
      "Epoch 8/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.1819 - accuracy: 0.9350\n",
      "Epoch 9/15\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.1527 - accuracy: 0.9461\n",
      "Epoch 10/15\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.1747 - accuracy: 0.9350\n",
      "Epoch 11/15\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.1647 - accuracy: 0.9389\n",
      "Epoch 12/15\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.1504 - accuracy: 0.9483\n",
      "Epoch 13/15\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.1500 - accuracy: 0.9456\n",
      "Epoch 14/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.1867 - accuracy: 0.9328\n",
      "Epoch 15/15\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.1284 - accuracy: 0.9572\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8250\n",
      "Test Loss: 0.3724156618118286\n",
      "Test Accuracy: 0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "#RANDOM SAMPLING WITHOUT REPLACEMENT\n",
    "print(f'Training data full size - {len(training_data)}')\n",
    "print(f'Testing data full size - {len(testing_data)}')\n",
    "\n",
    "#Parameters\n",
    "trainingDataSize = 1800\n",
    "testingDataSize = 200\n",
    "noEpochs = 15\n",
    "\n",
    "print(f'Training data sample size - {trainingDataSize}')\n",
    "print(f'Testing data sample size - {testingDataSize}')\n",
    "print(f'No. epochs selected - {noEpochs}')\n",
    "\n",
    "training_data_sample=[]\n",
    "training_labels_sample=[]\n",
    "\n",
    "testing_data_sample=[]\n",
    "testing_labels_sample=[]\n",
    "\n",
    "# Training data\n",
    "normal_indices = list(range(len(NormalTraining)))\n",
    "pneumonia_indices = list(range(len(PneumoniaTraining)))\n",
    "\n",
    "for i in tqdm(range(trainingDataSize), desc=\"Loading Training Data\"):\n",
    "    randNum = random.randint(0, 1)\n",
    "    if randNum == 0 and len(normal_indices) > 0:\n",
    "        randData = random.sample(normal_indices, 1)[0]\n",
    "        normal_indices.remove(randData)\n",
    "        training_data_sample.append(NormalTraining[randData])\n",
    "        training_labels_sample.append(0)\n",
    "    elif randNum == 1 and len(pneumonia_indices) > 0:\n",
    "        randData = random.sample(pneumonia_indices, 1)[0]\n",
    "        pneumonia_indices.remove(randData)\n",
    "        training_data_sample.append(PneumoniaTraining[randData])\n",
    "        training_labels_sample.append(1)\n",
    "        \n",
    "# Testing data\n",
    "normal_indices = list(range(len(NormalTesting)))\n",
    "pneumonia_indices = list(range(len(PneumoniaTesting)))\n",
    "\n",
    "for i in tqdm(range(testingDataSize), desc=\"Loading Testing Data\"):\n",
    "    randNum = random.randint(0, 1)\n",
    "    if randNum == 0 and len(normal_indices) > 0:\n",
    "        randData = random.sample(normal_indices, 1)[0]\n",
    "        normal_indices.remove(randData)\n",
    "        testing_data_sample.append(NormalTesting[randData])\n",
    "        testing_labels_sample.append(0)\n",
    "    elif randNum == 1 and len(pneumonia_indices) > 0:\n",
    "        randData = random.sample(pneumonia_indices, 1)[0]\n",
    "        pneumonia_indices.remove(randData)\n",
    "        testing_data_sample.append(PneumoniaTesting[randData])\n",
    "        testing_labels_sample.append(1)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, activation='tanh', input_dim=imageSize*imageSize))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Loading Model')\n",
    "model.fit(training_data_sample, training_labels_sample, epochs=noEpochs, batch_size=64)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(testing_data_sample, testing_labels_sample)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc35fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
